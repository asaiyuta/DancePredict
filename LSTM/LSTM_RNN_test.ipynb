{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import LSTMRNN\n",
    "import Batch_Gen_Mod\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinect_data exist shaped data csv\n",
      "batch_gen 002_shape_scale_100\n",
      "batch_gen exist pickle file data/002_shape_scale_100.pickle\n",
      "batch_gen length = 3840 dim = 75\n"
     ]
    }
   ],
   "source": [
    "batch_gen = Batch_Gen_Mod.kinect_data(\"data/002.csv\", 0.01).create_batch_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuutaasai/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-19c81a827959>:10: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from test_001_02.ckpt\n",
      "train_loss [0.091491334]\n",
      "train_loss [0.0342501]\n",
      "train_loss [0.028072858]\n",
      "train_loss [0.032384075]\n",
      "train_loss [0.03041013]\n",
      "train_loss [0.030998077]\n",
      "train_loss [0.024022872]\n",
      "train_loss [0.028611049]\n",
      "train_loss [0.028728154]\n",
      "train_loss [0.025200207]\n",
      "train_loss [0.022710504]\n",
      "train_loss [0.023407716]\n",
      "train_loss [0.02059848]\n",
      "train_loss [0.021044534]\n",
      "train_loss [0.021788899]\n",
      "train_loss [0.020423789]\n",
      "train_loss [0.01924675]\n",
      "train_loss [0.018961549]\n",
      "train_loss [0.022650247]\n",
      "train_loss [0.018457752]\n",
      "save sess\n"
     ]
    }
   ],
   "source": [
    "def train(num_of_epoch,  batch_size, learning_rate, num_layers, num_of_hidden_nodes):\n",
    "    input_ph, sup_ph, lstm_state_ph,cross_entropy, train_step, predict = LSTMRNN.lstm_dnn_construct(\n",
    "                                num_of_element = 75,\n",
    "                               num_of_hidden_nodes = num_of_hidden_nodes,\n",
    "                               num_layers = num_layers,\n",
    "                               num_of_frm = 45,\n",
    "                               hidden_size = [1000,500,100,75],\n",
    "                               leaning_rate = learning_rate)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"test_001_03.ckpt\")\n",
    "    for _ in range(num_of_epoch):\n",
    "        inputs, supervisors = batch_gen.get_train_batch(index=_, batch_size=batch_size , input_size=45, dist=15)\n",
    "        train_dict = {\n",
    "            input_ph:            inputs,\n",
    "            sup_ph:   supervisors,\n",
    "            lstm_state_ph:     np.zeros((num_layers, 2, batch_size, num_of_hidden_nodes)),\n",
    "        }\n",
    "        sess.run(train_step, feed_dict=train_dict)\n",
    "        if _ % 1000 == 0:\n",
    "            train_loss = sess.run([cross_entropy], feed_dict=train_dict)\n",
    "            print(\"train_loss\",train_loss)\n",
    "    print(\"save sess\")  \n",
    "    saver.save(sess, \"test_001_04.ckpt\")\n",
    "            \n",
    "train(num_of_epoch = 20000,  batch_size = 200, learning_rate = 0.0005, num_layers = 3, num_of_hidden_nodes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuutaasai/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-81848cb90249>:17: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "INFO:tensorflow:Restoring parameters from test_001_02.ckpt\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def write_csv( __data, __path):\n",
    "\t    with open(__path, 'w') as c:\n",
    "\t\t    writer = csv.writer(c, lineterminator='\\n')\n",
    "\t\t    writer.writerows(__data)\n",
    "            \n",
    "def predict( num_of_length, learning_rate, num_layers, num_of_hidden_nodes):\n",
    "    input_ph, sup_ph, lstm_state_ph,cross_entropy, train_step, predict = LSTMRNN.lstm_dnn_construct(\n",
    "                               num_of_element = 75,\n",
    "                               num_of_hidden_nodes = num_of_hidden_nodes,\n",
    "                               num_layers = num_layers,\n",
    "                               num_of_frm = 45,\n",
    "                               hidden_size = [1000,500,100,75],\n",
    "                               leaning_rate = learning_rate)\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"test_001_02.ckpt\")\n",
    "    data = []\n",
    "    for _ in range(num_of_length):\n",
    "        inputs, supervisors = batch_gen.get_train_batch(index=_, batch_size=1 , input_size=45, dist=15)\n",
    "        train_dict = {\n",
    "            input_ph:            inputs,\n",
    "            lstm_state_ph:     np.zeros((num_layers, 2, 1, num_of_hidden_nodes)),\n",
    "        }\n",
    "        p_data = sess.run(predict, feed_dict=train_dict)\n",
    "        data.append(p_data.tolist()[0])\n",
    "    write_csv(data, \"test_002_02_predict.csv\")\n",
    "    print(\"finish\")\n",
    "        \n",
    "predict(3000, learning_rate = 0.0005, num_layers = 3, num_of_hidden_nodes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
